{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26da59a",
   "metadata": {},
   "source": [
    "# Walmart Sales Analysis — Google Colab Notebook\n",
    "هذا الملف جاهز لرفعه أو لصقه في Google Colab. **قبل التشغيل**: ارفع ملف `Walmart.csv` باستخدام واجهة رفع الملفات في Colab (أو استخدم Google Drive).\n",
    "\n",
    "كل خلية تحتوي على شرح بالعربي يشرح ماذا يفعل الكود.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb1157",
   "metadata": {},
   "source": [
    "## 1) استيراد المكتبات المطلوبة\n",
    "**شرح:** هذه المكتبات ستستخدم لمعالجة البيانات، الرسم، وبناء النموذج."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f222fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استيراد المكتبات\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f93e3e7",
   "metadata": {},
   "source": [
    "## 2) رفع وقراءة الملف\n",
    "**شرح:** شغّل هذه الخلية لرفع `Walmart.csv` من جهازك إلى بيئة Colab ثم قراءة الملف.\n",
    "\n",
    "(بدلاً من الرفع يمكنك وضع الملف في Google Drive وربطه إذا أردت.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c569711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# رفع ملف CSV من جهازك (سيطلب منك اختيار الملف)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# بعد الرفع، اقرأ الملف\n",
    "import io, os\n",
    "if 'Walmart.csv' in uploaded:\n",
    "    df = pd.read_csv(io.BytesIO(uploaded['Walmart.csv']))\n",
    "else:\n",
    "    # حاول العثور على أي ملف CSV مرفوع\n",
    "    csv_files = [k for k in uploaded.keys() if k.lower().endswith('.csv')]\n",
    "    if len(csv_files) > 0:\n",
    "        df = pd.read_csv(io.BytesIO(uploaded[csv_files[0]]))\n",
    "    else:\n",
    "        raise FileNotFoundError('لم يتم العثور على Walmart.csv. ارفع الملف ثم شغّل الخلية مرة أخرى.')\n",
    "\n",
    "print('Loaded rows:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233f6cc",
   "metadata": {},
   "source": [
    "## 3) تحويل عمود التاريخ وتنظيف البيانات\n",
    "**شرح:** نحول عمود Date إلى نوع تواريخ، نحذف الصفوف الناقصة في الأعمدة الأساسية ونحول الأعمدة الرقمية لصيغ رقمية ونملأ المفقودات بالوسيط."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تحويل التاريخ وتنظيف القيم المفقودة\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# حذف أي صف لا يحتوي على تاريخ أو مبيعات\n",
    "df = df.dropna(subset=['Date', 'Weekly_Sales']).copy()\n",
    "\n",
    "# تحويل الأعمدة الرقمية والتعامل مع missing\n",
    "num_cols = ['Weekly_Sales','Temperature','Fuel_Price','CPI','Unemployment','Holiday_Flag']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# ملء القيم المفقودة بالوسيط للأعمدة العددية (إن وجدت)\n",
    "for c in ['Temperature','Fuel_Price','CPI','Unemployment']:\n",
    "    if c in df.columns:\n",
    "        df[c].fillna(df[c].median(), inplace=True)\n",
    "\n",
    "print('After cleaning: rows=', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681218fc",
   "metadata": {},
   "source": [
    "## 4) إنشاء ميزات زمنية\n",
    "**شرح:** نستخرج Year, Month, WeekOfYear من عمود التاريخ لاستخدامها كنماذج."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3498812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إنشاء ميزات زمنية\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['WeekOfYear'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "df[['Date','Year','Month','WeekOfYear']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b211fa",
   "metadata": {},
   "source": [
    "## 5) EDA — نظرة عامة\n",
    "**شرح:** عرض إحصائيات وصفية ومعلومات عن الأعمدة."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# نظرة عامة\n",
    "display(df.head())\n",
    "display(df.describe(include='all'))\n",
    "print('\\nInfo:')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11d620",
   "metadata": {},
   "source": [
    "## 6) EDA — توزيع المبيعات\n",
    "**شرح:** نرسم histogram لتوزيع Weekly_Sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70515ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# رسم توزيع Weekly_Sales\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df['Weekly_Sales'], bins=50)\n",
    "plt.title('Distribution of Weekly Sales')\n",
    "plt.xlabel('Weekly Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e4c41",
   "metadata": {},
   "source": [
    "## 7) تحليل الارتباط (Correlation)\n",
    "**شرح:** نحسب مصفوفة الارتباط بين المتغيرات الرقمية المهمة."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11565a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# مصفوفة الارتباط\n",
    "numeric_cols = ['Weekly_Sales','Temperature','Fuel_Price','CPI','Unemployment','Holiday_Flag','Year','Month','WeekOfYear']\n",
    "present_cols = [c for c in numeric_cols if c in df.columns]\n",
    "corr = df[present_cols].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d844f6",
   "metadata": {},
   "source": [
    "## 8) تجهيز بيانات النموذج\n",
    "**شرح:** نحدد المتغيرات المستقلة X والمتغير الهدف y، ونحول Store إلى دوال 0/1 (one-hot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb52f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تجهيز X و y\n",
    "features = ['Store','Holiday_Flag','Temperature','Fuel_Price','CPI','Unemployment','Year','Month','WeekOfYear']\n",
    "features = [f for f in features if f in df.columns]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['Weekly_Sales'].copy()\n",
    "\n",
    "# One-hot encode Store (إن وجد)\n",
    "if 'Store' in X.columns:\n",
    "    X = pd.get_dummies(X, columns=['Store'], prefix='Store', drop_first=True)\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3632e",
   "metadata": {},
   "source": [
    "## 9) Standardize الأرقام و تدريب نموذج RandomForest\n",
    "**شرح:** نطبق StandardScaler على الميزات العددية ثم ندرب RandomForest كـ baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features\n",
    "num_feats = ['Temperature','Fuel_Price','CPI','Unemployment','Year','Month','WeekOfYear']\n",
    "num_feats = [c for c in num_feats if c in X.columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if len(num_feats) > 0:\n",
    "    X.loc[:, num_feats] = scaler.fit_transform(X[num_feats])\n",
    "\n",
    "# تدريب RandomForest\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "\n",
    "# توقع على نفس البيانات (baseline quick check)\n",
    "y_pred = model.predict(X)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f'RMSE (train): {rmse:.2f}')\n",
    "print(f'R2 (train): {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edf866",
   "metadata": {},
   "source": [
    "## 10) أهمية المتغيرات (Feature Importance)\n",
    "**شرح:** نستخرج أهمية المتغيرات من نموذج RandomForest ونعرض أهم 20 متغيراً."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edb8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "display(importances.head(20))\n",
    "\n",
    "# رسم أهم المتغيرات\n",
    "plt.figure(figsize=(10,6))\n",
    "importances.head(20).plot(kind='barh')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 20 Feature Importances (RandomForest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35c2a0",
   "metadata": {},
   "source": [
    "## 11) حفظ النتائج والملفات (اختياري)\n",
    "**شرح:** لتحميل النتائج إلى جهازك، نفعل ZIP أو نحفظ ملفات منفردة. شغّل الخلية التالية إذا أردت حفظ artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حفظ ملفات النتائج داخل مجلد 'walmart_colab_output'\n",
    "import os, joblib, csv\n",
    "out_dir = 'walmart_colab_output'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# save artifacts\n",
    "df.head().to_csv(os.path.join(out_dir, 'head.csv'), index=False)\n",
    "df.describe().to_csv(os.path.join(out_dir, 'describe.csv'))\n",
    "corr.to_csv(os.path.join(out_dir, 'correlation_matrix.csv'))\n",
    "importances.head(50).to_csv(os.path.join(out_dir, 'feature_importances.csv'))\n",
    "joblib.dump(model, os.path.join(out_dir, 'random_forest_model.joblib'))\n",
    "print('Saved artifacts to', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc93bf6",
   "metadata": {},
   "source": [
    "## انتهى — ملاحظات أخيرة\n",
    "- هذا Notebook جاهز للتشغيل في Google Colab.\n",
    "- تأكد أن ترفع `Walmart.csv` قبل تشغيل الخلايا.\n",
    "- إذا تريد: أضيف خلية تقسم البيانات زمنياً لtrain/test وتقييم أفضل، أو أدرج GridSearch لتحسين الهايبرباراميترز.\n",
    "\n",
    "**لو تحب أعمل تعديل أو أضيف جزء، قلّي أي إضافة تريد.**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
